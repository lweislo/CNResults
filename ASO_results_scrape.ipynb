{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "letour_scrape.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lweislo/CNResults/blob/master/ASO_results_scrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbRkB5BCva-E",
        "colab_type": "text"
      },
      "source": [
        "# This page lets you scrape results directly from any LeTour.fr-formatted race.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9pay3arvZF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import html5lib\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tuKa9diYwZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Universal code for ASO race results\n",
        "\n",
        "tab_dict = {'ite':'Stage',\n",
        "'ipe':'Points',\n",
        "'ime':'Mountains',\n",
        "'ije':'Young riders',\n",
        "'ice':'Combativity',\n",
        "'ete':'Teams',\n",
        "'itg':'General Classification',\n",
        "'ipg':'Points Classification',\n",
        "'img':'Mountains Classification',\n",
        "'ijg':'Young Riders Classification',\n",
        "'icg':'Combativity Classification',\n",
        "'etg':'Teams Classification'}\n",
        "\n",
        "order_list = ['ite', 'ipe', 'ime', 'ije', 'ice', 'ete', 'itg', 'ipg', 'img', 'icg','ijg', 'etg']\n",
        "points_stg = ['ipe', 'ime']\n",
        "output_labels = []\n",
        "output_tables = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQDbq5BhmOb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_file(header_list, table_list):\n",
        "    outfile = input(\"Enter your desired CSV filename: \")\n",
        "    with open(outfile, 'w') as file:\n",
        "        for item in range(0, len(header_list)):\n",
        "            try:\n",
        "                file.write(f'\\n{header_list[item]}\\n')\n",
        "                file.write(table_list[item].to_csv(header=False, index=False, encoding='Latin-1'))\n",
        "            except:\n",
        "                pass\n",
        "    files.download(outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SipUfU0vZGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell scrapes the page for stage and extracts a list of raw URLs coded with the classification code\n",
        "\n",
        "def scrape_urls(stage_url):\n",
        "    base_url = stage_url.split('/')[2] #Race URL\n",
        "    stage_id = stage_url.split('/')[-1] #Stage\n",
        "    links_list = [] #Temporarily store the list of unparsed URLs\n",
        "    url_dict = {} #Dictionary with result type code and full URL\n",
        "    print(f\"Getting result links for {stage_url}\")\n",
        "\n",
        "    page = requests.get(stage_url)\n",
        "\n",
        "    if page.status_code == 200:\n",
        "        content = page.content\n",
        "        soup = BeautifulSoup(content, \"html5lib\")\n",
        "\n",
        "    #Pull out a specific block of code with two sets of coded URLs from the soup. YMMV if ASO change the format!\n",
        "        try:\n",
        "            all_links = soup.find(class_=\"ranking__tabs\") #This is from a UL tag above the table on the page\n",
        "            links = all_links.find_all(class_=\"tabs__link\") #There are two items in the list, stage and GC\n",
        "        except ElementDoesNotExist as e:\n",
        "            print(f\"That does not appear to be a valid results URL. {e}\")\n",
        "# Parse out the URLs from the list 'data-ajax-stack' attribute\n",
        "    for item in links:\n",
        "        urls = item.get('data-ajax-stack')\n",
        "        links_list.append(urls)\n",
        "\n",
        "\n",
        "    for item in links_list:\n",
        "          #clean up the code into a useable URL\n",
        "        urls = item.replace('\\'', '\"')\n",
        "        myurl = urls.replace('\\/', '/')\n",
        "        myurls = json.loads(myurl)\n",
        "        for key, value in myurls.items():\n",
        "            url_dict[key] = f\"https://{base_url}{value}\"\n",
        "            \n",
        "    for item in order_list:   # IMPORTANT: We want to process these in the order of the universal result order list \n",
        "        try:\n",
        "            print(f\"Scraping results from {tab_dict[item]}\")\n",
        "            scrape_results(item, url_dict[item])\n",
        "        except KeyError:\n",
        "            print(f\"No results for {tab_dict[item]}\")\n",
        "            pass\n",
        "    return output_labels, output_tables"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKwUVZd6vZGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def scrape_results(item, url):\n",
        "    print(f\"Getting results for {item}, {url}\")\n",
        "    out_df = pd.DataFrame()\n",
        "    try:\n",
        "        page = requests.get(url).content\n",
        "        soup = BeautifulSoup(page, \"html5lib\")\n",
        "#Treat sprint and mountains stage results differently, they have multiple tables per page\n",
        "        if item == 'ipe' or item == 'ime':\n",
        "            l_list = []\n",
        "            t_list = []\n",
        "\n",
        "            if item == 'ipe':\n",
        "                name = \"Sprint\"\n",
        "            else:\n",
        "                name = \"Mountain\"\n",
        "            print(f\"Found a {name}\")\n",
        "            mydiv = soup.find(class_=\"tabs__content\")\n",
        "            labels = mydiv.find_all(class_=\"rankingTables__caption\")\n",
        "            tables = mydiv.find_all(class_=\"rankingTable\")\n",
        "\n",
        "            for item in labels:\n",
        "                try:\n",
        "                    this_label = item.text.title()\n",
        "                    this_label = this_label.replace(\" Km\", \"\").replace(\" - \",\" km. \")\n",
        "                    this_label = (f\"{name} {labels.index(item)+1} - {this_label}\")\n",
        "                    print(this_label)\n",
        "                    output_labels.append(this_label)\n",
        "                except ValueError:\n",
        "                    pass\n",
        "\n",
        "            for item in tables:\n",
        "                out_df = pd.DataFrame()\n",
        "                try:\n",
        "                    table = pd.read_html(str(item), index_col=None, header=None)\n",
        "                    table = table[0]\n",
        "                    out_df['Place'] = table['Rank']\n",
        "                    out_df['Bib'] = table['Rider No.'].fillna('')\n",
        "                    out_df['Points'] = table['Points'].str.replace('PTS', '')\n",
        "                    print(out_df)\n",
        "                    output_tables.append(out_df)\n",
        "                except ValueError:\n",
        "                    pass        \n",
        "        else:\n",
        "            # Fish the tables out of the soup\n",
        "            res_table = pd.read_html(page)\n",
        "            df = res_table[0]\n",
        "            # Get the heading for output\n",
        "            label = tab_dict[item]\n",
        "            output_labels.append(label)\n",
        "            # Get the table for output\n",
        "            if item in ['ite', 'ije', 'itg', 'ijg']:\n",
        "                out_df['Place'] = df['Rank'].fillna('')\n",
        "                out_df['Bib'] = df['Rider No.'].fillna('')\n",
        "                out_df['Result'] = df['Times'].str.replace('h ', ':').str.replace('\\'\\'', '').str.replace('\\' ',':')\n",
        "            elif item in ['ipg', 'img']:\n",
        "                out_df['Place'] = df['Rank'].fillna('')\n",
        "                out_df['Bib'] = df['Rider No.'].fillna('')\n",
        "                out_df['Result'] = df['Points'].str.replace(' PTS', '')\n",
        "            elif item == 'ice':\n",
        "                out_df['Place'] = df['Rank'].fillna('')\n",
        "                out_df['Bib'] = df['Rider No.'].fillna('')\n",
        "                out_df['Result'] = ''\n",
        "            elif item in ['ete', 'etg']:\n",
        "                out_df['Place'] = df['Rank'].fillna('')\n",
        "                out_df['Bib'] = df['Team'].str.title().fillna('')\n",
        "                out_df['Result'] = df['Times'].str.replace('h ', ':').str.replace('\\'\\'', '').str.replace('\\' ',':')\n",
        "            #out_df = df[df.columns[-3:]]\n",
        "#             output_res(out_df, label)\n",
        "            output_tables.append(out_df)\n",
        "\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"No table found for \" + item)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgEaDb3pLevA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def start():\n",
        "    stage_url = input(\"Enter the URL to LeTour results eg. https://www.tour-de-yorkshire.co.uk/en/rankings/stage-2:\")\n",
        "    scrape_urls(stage_url)\n",
        "    output_file(output_labels, output_tables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSxYrCb2T3vg",
        "colab_type": "code",
        "outputId": "87e54a57-091c-4b98-bee4-51b26a3df1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "start()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the URL to LeTour results eg. https://www.tour-de-yorkshire.co.uk/en/rankings/stage-2:https://www.tour-de-yorkshire.co.uk/en/rankings/stage-2\n",
            "Getting result links for https://www.tour-de-yorkshire.co.uk/en/rankings/stage-2\n",
            "Scraping results from Stage\n",
            "Getting results for ite, https://www.tour-de-yorkshire.co.uk/en/ajax/ranking/2/ite/6f21d73eddddbb74e35c0113a43935ca/none\n",
            "Scraping results from Points\n",
            "Getting results for ipe, https://www.tour-de-yorkshire.co.uk/en/ajax/ranking/2/ipe/b7b8a6ce4bba7b1390561280c900d179/none\n",
            "Found a Sprint\n",
            "Sprint 1 - Pontefract km. 20.5\n",
            "Sprint 2 - A61 Harrogate km. 84.5\n",
            "Sprint 3 - Bedale km. 132\n",
            "   Place  Bib Points\n",
            "0      1  121     5 \n",
            "1      2  145     3 \n",
            "2      3  165     1 \n",
            "   Place  Bib Points\n",
            "0      1  145     5 \n",
            "1      2  165     3 \n",
            "2      3  121     1 \n",
            "   Place  Bib Points\n",
            "0      1   45    15 \n",
            "1      2  136    12 \n",
            "2      3   16     9 \n",
            "3      4  126     7 \n",
            "4      5  181     6 \n",
            "5      6  155     5 \n",
            "6      7   87     4 \n",
            "7      8  115     3 \n",
            "8      9   93     2 \n",
            "9     10   51     1 \n",
            "Scraping results from Mountains\n",
            "Getting results for ime, https://www.tour-de-yorkshire.co.uk/en/ajax/ranking/2/ime/e85c463644dbc71dd7c047b005fb27d8/none\n",
            "Found a Mountain\n",
            "Scraping results from Young riders\n",
            "No results for Young riders\n",
            "Scraping results from Combativity\n",
            "Getting results for ice, https://www.tour-de-yorkshire.co.uk/en/ajax/ranking/2/ice/d984f2c25650e56b7af840291c00ec43/none\n",
            "Scraping results from Teams\n",
            "Getting results for ete, https://www.tour-de-yorkshire.co.uk/en/ajax/ranking/2/ete/d8a79ac4fbfcc06476b26bb98e4d39b5/none\n",
            "Scraping results from General Classification\n",
            "Getting results for itg, https://www.tour-de-yorkshire.co.uk/en/ajax/ranking/2/itg/fca07fb6b35baa3d6dfe2d4500ea91ed/none\n",
            "Scraping results from Points Classification\n",
            "Getting results for ipg, https://www.tour-de-yorkshire.co.uk/en/ajax/ranking/2/ipg/911729cf582be501a97e41ac2bb6a040/none\n",
            "Scraping results from Mountains Classification\n",
            "Getting results for img, https://www.tour-de-yorkshire.co.uk/en/ajax/ranking/2/img/fe40aebbf8475ef7d5f9415e1b371b9d/none\n",
            "Scraping results from Combativity Classification\n",
            "No results for Combativity Classification\n",
            "Scraping results from Young Riders Classification\n",
            "No results for Young Riders Classification\n",
            "Scraping results from Teams Classification\n",
            "Getting results for etg, https://www.tour-de-yorkshire.co.uk/en/ajax/ranking/2/etg/a6726c4a9d04e10e31f78676fcebd5cd/none\n",
            "Enter your desired CSV filename: test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w14lMGchpWIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}