{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "giro2019results.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lweislo/CNResults/blob/master/giro2019results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDGLi4mJLGHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# STEP 1: CLICK PLAY IN THE UPPER LEFT OF THIS CELL (click in the cell first to see the icon or just shift-enter)\n",
        "# It will take a little bit to go through loading all the requirements.\n",
        "# Then go to the next cell and click play - nothing will happen that's obvious there.\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "!pip install splinter\n",
        "from splinter import Browser\n",
        "from splinter.exceptions import ElementDoesNotExist\n",
        "from google.colab import files\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from time import sleep\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwwQK9hR75zB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# STEP 2: CLICK PLAY ON THIS CELL. This just loads the program. Then scroll to next cell.\n",
        "\n",
        "def output_file(header_list, table_list):\n",
        "    outfile = input(\"Enter your desired CSV filename: \" or \"giro_results.csv\")\n",
        "    with open(outfile, 'w') as file:\n",
        "        for item in range(0, len(header_list)):\n",
        "            try:\n",
        "                file.write(f'\\n {header_list[item]}\\n')\n",
        "                file.write(table_list[item].to_csv(header=False, index=False, encoding='UTF-8'))\n",
        "            except:\n",
        "                pass\n",
        "    print(\"Note, the accented characters will get munged if you open directly in Excel.\")\n",
        "    print(\"Open in TextMate first, remove quotes, and save file in Western Latin-1 format.\")\n",
        "    files.download(outfile)\n",
        "def init_browser():\n",
        "    # Mac-specific browser init\n",
        "    options = Options()\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    driver = webdriver.Chrome('chromedriver', options=options)\n",
        "    return driver\n",
        "def format_tables(headers, table_list):\n",
        "\n",
        "    print(\"Please upload the gironames.csv file.\")\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "        macro_file=fn\n",
        "    macro = pd.read_csv(macro_file, header=None, index_col=False, names=['name','value'])\n",
        "    macros = macro.set_index('name').to_dict()['value']\n",
        "\n",
        "    for item in range(0, len(table_list)):\n",
        "        if \"Tempo\" in table_list[item]:\n",
        "            table_list[item] = table_list[item][[\"Unnamed: 1\", \"Corridore\",\"Tempo\"]]\n",
        "            table_list[item][\"Tempo\"] = table_list[item][\"Tempo\"].str.replace(\"h \", \":\").str.replace(\"\\’ \",\":\").str.replace(\"”\", \"\")\n",
        "        elif \"punti\" in table_list[item]:\n",
        "            table_list[item] = table_list[item][[\"Unnamed: 1\", \"Corridore\",\"punti\"]]\n",
        "        elif \"Team.1\" in table_list[item]:\n",
        "            table_list[item] = table_list[item][[\"Unnamed: 1\", \"Corridore\"]]\n",
        "\n",
        "    for item in table_list:\n",
        "        item['Corridore'] = item['Corridore'].map(macros).fillna(item['Corridore'])\n",
        "\n",
        "    header_list = []\n",
        "    for item in headers:\n",
        "        header_list.append(item.split(\"| \")[1].split(\" (Ufficiale)\")[0])\n",
        "    print(\"Outputting results\")\n",
        "    output_file(header_list, table_list)\n",
        "    \n",
        "def parse_tables(stage_tables):\n",
        "    headers = []\n",
        "    table_list = []\n",
        "    for n in range(1,3):    \n",
        "        for item in stage_tables[n]:\n",
        "            try:\n",
        "                head = item.find('h2').get_text()\n",
        "                headers.append(head)\n",
        "                tables = item.find('table')\n",
        "                table_list.append(pd.read_html(str(tables))[0])\n",
        "                print(f\"Formatting results for {head}\")\n",
        "            except:\n",
        "                print(\"No valid results found, sorry\")\n",
        "                pass\n",
        "    format_tables(headers, table_list)\n",
        "def scrape_giro(stage):\n",
        "    browser = init_browser()\n",
        "    browser.get(stage)\n",
        "    print(\"Getting results from Giro\")\n",
        "    sleep(5)\n",
        "    # Scrape the page\n",
        "    soup = BeautifulSoup(browser.page_source, 'lxml')\n",
        "    try:\n",
        "        stage_tables = soup.find_all('div', class_='tabs-content')\n",
        "        print(\"Parsing results\")\n",
        "    except ElementDoesNotExist:\n",
        "        print(\"Results not found\")\n",
        "    parse_tables(stage_tables)\n",
        "\n",
        "def start():\n",
        "    \n",
        "    print(\"Enter http://www.giroditalia.it/it/classifiche/ or to enter a different stage, right click on the stage link on Giro page\\\n",
        "    and paste that URL here\")\n",
        "    stage = input(\"Enter the URL\")\n",
        "    scrape_giro(stage)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60KLqOGo83Rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}