{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import html5lib\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = {'e':'Stage', 'g':'General Classification'}\n",
    "tab_dict = {'ite':'Stage',\n",
    "'ipe':'Points',\n",
    "'ime':'Mountains',\n",
    "'ije':'Young riders',\n",
    "'ice':'Combativity',\n",
    "'ete':'Teams',\n",
    "'itg':'General Classification',\n",
    "'ipg':'Points Classification',\n",
    "'img':'Mountains Classification',\n",
    "'ijg':'Young Riders Classification',\n",
    "'icg':'Combativity Classification',\n",
    "'etg':'Teams Classification'}\n",
    "\n",
    "order_list = ['ite', 'ipe', 'ime', 'ije', 'ice', 'ete', 'itg', 'ipg', 'img', 'ijg', 'etg', 'icg']\n",
    "points_stg = ['ipe', 'ime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_res(df, label):\n",
    "\n",
    "    with open(f'{outfile}','a+') as output:\n",
    "        output.write(label + '\\n')\n",
    "        df.to_csv(output, header=False, sep = \"\\t\", index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(url_dict):\n",
    "    count = 0\n",
    "    label = ''\n",
    "\n",
    "    for l_item in order_list:\n",
    "        url = url_dict[l_item]\n",
    "        r_type = tab_dict[l_item]\n",
    "        print(\"Getting the data for: \" + r_type)\n",
    "\n",
    "        try:\n",
    "    #Treat sprint and mountains stage results differently\n",
    "    #They have multiple tables per page\n",
    "            if l_item != 'ipe' or l_item != 'ime':\n",
    "                page = requests.get(url).content\n",
    "                soup = BeautifulSoup(page, \"html5lib\")\n",
    "                res_table = pd.read_html(page)\n",
    "                df = res_table[0]\n",
    "                label = r_type\n",
    "\n",
    "                if l_item in ['ite', 'ije', 'itg', 'ijg']:\n",
    "                    out_df['Place'] = df['Rank'].fillna('')\n",
    "                    out_df['Bib'] = df['Rider No.'].fillna('')\n",
    "                    out_df['Result'] = df['Times'].str.replace('h ', ':').str.replace('\\'\\'', '').str.replace('\\' ',':')\n",
    "                elif l_item in ['ipg', 'img']:\n",
    "                    out_df['Place'] = df['Rank'].fillna('')\n",
    "                    out_df['Bib'] = df['Rider No.'].fillna('')\n",
    "                    out_df['Result'] = df['Points'].str.replace(' PTS', '')\n",
    "                elif l_item == 'ice':\n",
    "                    out_df['Place'] = df['Rank'].fillna('')\n",
    "                    out_df['Bib'] = df['Rider No.'].fillna('')\n",
    "                    out_df['Result'] = ''\n",
    "                elif l_item in ['ete', 'etg']:\n",
    "                    out_df['Place'] = df['Rank'].fillna('')\n",
    "                    out_df['Bib'] = df['Team'].str.title().fillna('')\n",
    "                    out_df['Result'] = df['Times'].str.replace('h ', ':').str.replace('\\'\\'', '').str.replace('\\' ',':')\n",
    "#Augh, now the goddamn output has the same number of rows for every set.\n",
    "                #out_df = df[df.columns[-3:]]\n",
    "                output_res(out_df, label)\n",
    "\n",
    "            else:\n",
    "                page = requests.get(url).content\n",
    "                soup = BeautifulSoup(page, \"html5lib\")\n",
    "                tables = soup.find(class_=\"tabs__content\")\n",
    "                for item in tables.find_all(class_=\"rankingTables__caption\"):\n",
    "                    count +=1\n",
    "                    label = (r_type + ' ' + str(count) + ' - ')\n",
    "                    header = item.text.title()\n",
    "        #Using the page content, grab the tables.\n",
    "                    res_table = pd.read_html(page)\n",
    "                    df = res_table[0]\n",
    "                    out_df['Place'] = df['Rank'].fillna('')\n",
    "                    out_df['Bib'] = df['Team'].fillna('')\n",
    "                    out_df['Result'] = df['Points'].str.replace('PTS', '')\n",
    "                    #out_df = df[df.columns[-3:]]\n",
    "                    label = (header + label)\n",
    "                    output_res(out_df, label)\n",
    "                    label = ''\n",
    "\n",
    "        except TypeError:\n",
    "            print(\"No table found for \" + r_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(all_links):\n",
    "    url_dict = {}\n",
    "\n",
    "    for item in all_links[::-1]:\n",
    "        myurl = item['data-ajax-stack']\n",
    "        #clean up the code into a useable URL\n",
    "        badchr = ('{', '}', '\"')\n",
    "        for item in badchr:\n",
    "            myurl = myurl.replace(item, '')\n",
    "            myurl = myurl.replace('\\/', '/')\n",
    "        myurl = dict(x.split(':') for x in myurl.split(','))\n",
    "    myurls = {k:f'http://{base_url}{v}' for (k,v) in myurl.items()}\n",
    "#     print(myurls)\n",
    "\n",
    "#         print(url_dict)\n",
    "#     get_results(url_dict)\n",
    "#myurl is now a dictionary with TLA for result type:URL to results (key:value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    #Get the html from the page\n",
    "    page = requests.get(start_url)\n",
    "    content = page.content\n",
    "    soup = BeautifulSoup(content, \"html5lib\")\n",
    "    #Pull out a specific block of code with two sets of coded URLs.\n",
    "    all_links = soup.find_all(class_=\"tabs__link js-tabs-ranking\")\n",
    "\n",
    "    if len(all_links) == 0:\n",
    "        print(\"That doesn't appear to be an ASO results page as we know it.\")\n",
    "    else:\n",
    "        get_urls(all_links)\n",
    "\n",
    "try:\n",
    "    start_url = 'https://www.paris-nice.fr/en/rankings/stage-2' #input(\"Enter the results URL: \")\n",
    "    base_url = start_url.split('/')[2]\n",
    "    outfile = (start_url.split('www.')[1].split('.')[0] + '_'+ start_url.split('/')[-1] + '.csv')\n",
    "\n",
    "except:\n",
    "    print(\"That does not appear to be a valid results URL.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"tabs__link js-tabs-ranking\" data-ajax-stack='{\"itg\":\"\\/en\\/ajax\\/ranking\\/2\\/itg\\/fca07fb6b35baa3d6dfe2d4500ea91ed\\/none\",\"ipg\":\"\\/en\\/ajax\\/ranking\\/2\\/ipg\\/911729cf582be501a97e41ac2bb6a040\\/none\",\"etg\":\"\\/en\\/ajax\\/ranking\\/2\\/etg\\/a6726c4a9d04e10e31f78676fcebd5cd\\/none\",\"img\":\"\\/en\\/ajax\\/ranking\\/2\\/img\\/fe40aebbf8475ef7d5f9415e1b371b9d\\/none\",\"ijg\":\"\\/en\\/ajax\\/ranking\\/2\\/ijg\\/a963a600a2e13db0ca782ee089b4e010\\/none\"}' data-type=\"g\" data-xtclick=\"ranking::tab::overall\" href=\"it\">General classification</a>, <a class=\"tabs__link js-tabs-ranking\" data-ajax-stack='{\"ite\":\"\\/en\\/ajax\\/ranking\\/2\\/ite\\/6f21d73eddddbb74e35c0113a43935ca\\/none\",\"ipe\":\"\\/en\\/ajax\\/ranking\\/2\\/ipe\\/b7b8a6ce4bba7b1390561280c900d179\\/none\",\"ete\":\"\\/en\\/ajax\\/ranking\\/2\\/ete\\/d8a79ac4fbfcc06476b26bb98e4d39b5\\/none\",\"ime\":\"\\/en\\/ajax\\/ranking\\/2\\/ime\\/e85c463644dbc71dd7c047b005fb27d8\\/none\",\"ije\":\"\\/en\\/ajax\\/ranking\\/2\\/ije\\/a2201afcefd73c51359efff767231b1a\\/none\"}' data-type=\"e\" data-xtclick=\"ranking::tab::stage\" href=\"it\">Stage classification</a>]\n"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
